{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "32529116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron classification accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X, y = datasets.make_blobs(n_samples=1500, n_features= 4, centers = 2, cluster_std = 1.05, random_state =2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.9, random_state =123)\n",
    "\n",
    "\n",
    "p = Perceptron(learning_rate=0.01, n_iters=1)\n",
    "p.fit_sigmoid(X_train, y_train)\n",
    "predictions = p.predict_sigmoid(X_test)\n",
    "\n",
    "print(\"Perceptron classification accuracy\", accuracy(y_test, predictions))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "2baa799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.empty((np.array([1,3,4]).size,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "512c9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dcf1797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.6, 1.4, 0.2, 0. ],\n",
       "       [5.4, 3.9, 1.7, 0.4, 0. ],\n",
       "       [4.6, 3.4, 1.4, 0.3, 0. ],\n",
       "       [5. , 3.4, 1.5, 0.2, 0. ],\n",
       "       [4.4, 2.9, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [5.4, 3.7, 1.5, 0.2, 0. ],\n",
       "       [4.8, 3.4, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.1, 0. ],\n",
       "       [4.3, 3. , 1.1, 0.1, 0. ],\n",
       "       [5.8, 4. , 1.2, 0.2, 0. ],\n",
       "       [5.7, 4.4, 1.5, 0.4, 0. ],\n",
       "       [5.4, 3.9, 1.3, 0.4, 0. ],\n",
       "       [5.1, 3.5, 1.4, 0.3, 0. ],\n",
       "       [5.7, 3.8, 1.7, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.5, 0.3, 0. ],\n",
       "       [5.4, 3.4, 1.7, 0.2, 0. ],\n",
       "       [5.1, 3.7, 1.5, 0.4, 0. ],\n",
       "       [4.6, 3.6, 1. , 0.2, 0. ],\n",
       "       [5.1, 3.3, 1.7, 0.5, 0. ],\n",
       "       [4.8, 3.4, 1.9, 0.2, 0. ],\n",
       "       [5. , 3. , 1.6, 0.2, 0. ],\n",
       "       [5. , 3.4, 1.6, 0.4, 0. ],\n",
       "       [5.2, 3.5, 1.5, 0.2, 0. ],\n",
       "       [5.2, 3.4, 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3.1, 1.6, 0.2, 0. ],\n",
       "       [5.4, 3.4, 1.5, 0.4, 0. ],\n",
       "       [5.2, 4.1, 1.5, 0.1, 0. ],\n",
       "       [5.5, 4.2, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [5. , 3.2, 1.2, 0.2, 0. ],\n",
       "       [5.5, 3.5, 1.3, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [4.4, 3. , 1.3, 0.2, 0. ],\n",
       "       [5.1, 3.4, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.3, 0.3, 0. ],\n",
       "       [4.5, 2.3, 1.3, 0.3, 0. ],\n",
       "       [4.4, 3.2, 1.3, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.6, 0.6, 0. ],\n",
       "       [5.1, 3.8, 1.9, 0.4, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.6, 0.2, 0. ],\n",
       "       [4.6, 3.2, 1.4, 0.2, 0. ],\n",
       "       [5.3, 3.7, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.3, 1.4, 0.2, 0. ],\n",
       "       [7. , 3.2, 4.7, 1.4, 1. ],\n",
       "       [6.4, 3.2, 4.5, 1.5, 1. ],\n",
       "       [6.9, 3.1, 4.9, 1.5, 1. ],\n",
       "       [5.5, 2.3, 4. , 1.3, 1. ],\n",
       "       [6.5, 2.8, 4.6, 1.5, 1. ],\n",
       "       [5.7, 2.8, 4.5, 1.3, 1. ],\n",
       "       [6.3, 3.3, 4.7, 1.6, 1. ],\n",
       "       [4.9, 2.4, 3.3, 1. , 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3, 1. ],\n",
       "       [5.2, 2.7, 3.9, 1.4, 1. ],\n",
       "       [5. , 2. , 3.5, 1. , 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5, 1. ],\n",
       "       [6. , 2.2, 4. , 1. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4, 1. ],\n",
       "       [5.6, 2.9, 3.6, 1.3, 1. ],\n",
       "       [6.7, 3.1, 4.4, 1.4, 1. ],\n",
       "       [5.6, 3. , 4.5, 1.5, 1. ],\n",
       "       [5.8, 2.7, 4.1, 1. , 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5, 1. ],\n",
       "       [5.6, 2.5, 3.9, 1.1, 1. ],\n",
       "       [5.9, 3.2, 4.8, 1.8, 1. ],\n",
       "       [6.1, 2.8, 4. , 1.3, 1. ],\n",
       "       [6.3, 2.5, 4.9, 1.5, 1. ],\n",
       "       [6.1, 2.8, 4.7, 1.2, 1. ],\n",
       "       [6.4, 2.9, 4.3, 1.3, 1. ],\n",
       "       [6.6, 3. , 4.4, 1.4, 1. ],\n",
       "       [6.8, 2.8, 4.8, 1.4, 1. ],\n",
       "       [6.7, 3. , 5. , 1.7, 1. ],\n",
       "       [6. , 2.9, 4.5, 1.5, 1. ],\n",
       "       [5.7, 2.6, 3.5, 1. , 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1, 1. ],\n",
       "       [5.5, 2.4, 3.7, 1. , 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2, 1. ],\n",
       "       [6. , 2.7, 5.1, 1.6, 1. ],\n",
       "       [5.4, 3. , 4.5, 1.5, 1. ],\n",
       "       [6. , 3.4, 4.5, 1.6, 1. ],\n",
       "       [6.7, 3.1, 4.7, 1.5, 1. ],\n",
       "       [6.3, 2.3, 4.4, 1.3, 1. ],\n",
       "       [5.6, 3. , 4.1, 1.3, 1. ],\n",
       "       [5.5, 2.5, 4. , 1.3, 1. ],\n",
       "       [5.5, 2.6, 4.4, 1.2, 1. ],\n",
       "       [6.1, 3. , 4.6, 1.4, 1. ],\n",
       "       [5.8, 2.6, 4. , 1.2, 1. ],\n",
       "       [5. , 2.3, 3.3, 1. , 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3, 1. ],\n",
       "       [5.7, 3. , 4.2, 1.2, 1. ],\n",
       "       [5.7, 2.9, 4.2, 1.3, 1. ],\n",
       "       [6.2, 2.9, 4.3, 1.3, 1. ],\n",
       "       [5.1, 2.5, 3. , 1.1, 1. ],\n",
       "       [5.7, 2.8, 4.1, 1.3, 1. ],\n",
       "       [6.3, 3.3, 6. , 2.5, 1. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 1. ],\n",
       "       [7.1, 3. , 5.9, 2.1, 1. ],\n",
       "       [6.3, 2.9, 5.6, 1.8, 1. ],\n",
       "       [6.5, 3. , 5.8, 2.2, 1. ],\n",
       "       [7.6, 3. , 6.6, 2.1, 1. ],\n",
       "       [4.9, 2.5, 4.5, 1.7, 1. ],\n",
       "       [7.3, 2.9, 6.3, 1.8, 1. ],\n",
       "       [6.7, 2.5, 5.8, 1.8, 1. ],\n",
       "       [7.2, 3.6, 6.1, 2.5, 1. ],\n",
       "       [6.5, 3.2, 5.1, 2. , 1. ],\n",
       "       [6.4, 2.7, 5.3, 1.9, 1. ],\n",
       "       [6.8, 3. , 5.5, 2.1, 1. ],\n",
       "       [5.7, 2.5, 5. , 2. , 1. ],\n",
       "       [5.8, 2.8, 5.1, 2.4, 1. ],\n",
       "       [6.4, 3.2, 5.3, 2.3, 1. ],\n",
       "       [6.5, 3. , 5.5, 1.8, 1. ],\n",
       "       [7.7, 3.8, 6.7, 2.2, 1. ],\n",
       "       [7.7, 2.6, 6.9, 2.3, 1. ],\n",
       "       [6. , 2.2, 5. , 1.5, 1. ],\n",
       "       [6.9, 3.2, 5.7, 2.3, 1. ],\n",
       "       [5.6, 2.8, 4.9, 2. , 1. ],\n",
       "       [7.7, 2.8, 6.7, 2. , 1. ],\n",
       "       [6.3, 2.7, 4.9, 1.8, 1. ],\n",
       "       [6.7, 3.3, 5.7, 2.1, 1. ],\n",
       "       [7.2, 3.2, 6. , 1.8, 1. ],\n",
       "       [6.2, 2.8, 4.8, 1.8, 1. ],\n",
       "       [6.1, 3. , 4.9, 1.8, 1. ],\n",
       "       [6.4, 2.8, 5.6, 2.1, 1. ],\n",
       "       [7.2, 3. , 5.8, 1.6, 1. ],\n",
       "       [7.4, 2.8, 6.1, 1.9, 1. ],\n",
       "       [7.9, 3.8, 6.4, 2. , 1. ],\n",
       "       [6.4, 2.8, 5.6, 2.2, 1. ],\n",
       "       [6.3, 2.8, 5.1, 1.5, 1. ],\n",
       "       [6.1, 2.6, 5.6, 1.4, 1. ],\n",
       "       [7.7, 3. , 6.1, 2.3, 1. ],\n",
       "       [6.3, 3.4, 5.6, 2.4, 1. ],\n",
       "       [6.4, 3.1, 5.5, 1.8, 1. ],\n",
       "       [6. , 3. , 4.8, 1.8, 1. ],\n",
       "       [6.9, 3.1, 5.4, 2.1, 1. ],\n",
       "       [6.7, 3.1, 5.6, 2.4, 1. ],\n",
       "       [6.9, 3.1, 5.1, 2.3, 1. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 1. ],\n",
       "       [6.8, 3.2, 5.9, 2.3, 1. ],\n",
       "       [6.7, 3.3, 5.7, 2.5, 1. ],\n",
       "       [6.7, 3. , 5.2, 2.3, 1. ],\n",
       "       [6.3, 2.5, 5. , 1.9, 1. ],\n",
       "       [6.5, 3. , 5.2, 2. , 1. ],\n",
       "       [6.2, 3.4, 5.4, 2.3, 1. ],\n",
       "       [5.9, 3. , 5.1, 1.8, 1. ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"iris_data\", sep = \",\", header = None)\n",
    "data1.columns =  ['sep_len', 'sep_wid', 'pet_len', 'pet_wid', 'class']\n",
    "data1['class'] = data1['class'].replace(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], [0, 1, 1])\n",
    "\n",
    "\n",
    "data1 = data1.to_numpy()\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "864a019e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7. , 3.2, 4.7, 1.4, 0. ],\n",
       "       [6.4, 3.2, 4.5, 1.5, 0. ],\n",
       "       [6.9, 3.1, 4.9, 1.5, 0. ],\n",
       "       [5.5, 2.3, 4. , 1.3, 0. ],\n",
       "       [6.5, 2.8, 4.6, 1.5, 0. ],\n",
       "       [5.7, 2.8, 4.5, 1.3, 0. ],\n",
       "       [6.3, 3.3, 4.7, 1.6, 0. ],\n",
       "       [4.9, 2.4, 3.3, 1. , 0. ],\n",
       "       [6.6, 2.9, 4.6, 1.3, 0. ],\n",
       "       [5.2, 2.7, 3.9, 1.4, 0. ],\n",
       "       [5. , 2. , 3.5, 1. , 0. ],\n",
       "       [5.9, 3. , 4.2, 1.5, 0. ],\n",
       "       [6. , 2.2, 4. , 1. , 0. ],\n",
       "       [6.1, 2.9, 4.7, 1.4, 0. ],\n",
       "       [5.6, 2.9, 3.6, 1.3, 0. ],\n",
       "       [6.7, 3.1, 4.4, 1.4, 0. ],\n",
       "       [5.6, 3. , 4.5, 1.5, 0. ],\n",
       "       [5.8, 2.7, 4.1, 1. , 0. ],\n",
       "       [6.2, 2.2, 4.5, 1.5, 0. ],\n",
       "       [5.6, 2.5, 3.9, 1.1, 0. ],\n",
       "       [5.9, 3.2, 4.8, 1.8, 0. ],\n",
       "       [6.1, 2.8, 4. , 1.3, 0. ],\n",
       "       [6.3, 2.5, 4.9, 1.5, 0. ],\n",
       "       [6.1, 2.8, 4.7, 1.2, 0. ],\n",
       "       [6.4, 2.9, 4.3, 1.3, 0. ],\n",
       "       [6.6, 3. , 4.4, 1.4, 0. ],\n",
       "       [6.8, 2.8, 4.8, 1.4, 0. ],\n",
       "       [6.7, 3. , 5. , 1.7, 0. ],\n",
       "       [6. , 2.9, 4.5, 1.5, 0. ],\n",
       "       [5.7, 2.6, 3.5, 1. , 0. ],\n",
       "       [5.5, 2.4, 3.8, 1.1, 0. ],\n",
       "       [5.5, 2.4, 3.7, 1. , 0. ],\n",
       "       [5.8, 2.7, 3.9, 1.2, 0. ],\n",
       "       [6. , 2.7, 5.1, 1.6, 0. ],\n",
       "       [5.4, 3. , 4.5, 1.5, 0. ],\n",
       "       [6. , 3.4, 4.5, 1.6, 0. ],\n",
       "       [6.7, 3.1, 4.7, 1.5, 0. ],\n",
       "       [6.3, 2.3, 4.4, 1.3, 0. ],\n",
       "       [5.6, 3. , 4.1, 1.3, 0. ],\n",
       "       [5.5, 2.5, 4. , 1.3, 0. ],\n",
       "       [5.5, 2.6, 4.4, 1.2, 0. ],\n",
       "       [6.1, 3. , 4.6, 1.4, 0. ],\n",
       "       [5.8, 2.6, 4. , 1.2, 0. ],\n",
       "       [5. , 2.3, 3.3, 1. , 0. ],\n",
       "       [5.6, 2.7, 4.2, 1.3, 0. ],\n",
       "       [5.7, 3. , 4.2, 1.2, 0. ],\n",
       "       [5.7, 2.9, 4.2, 1.3, 0. ],\n",
       "       [6.2, 2.9, 4.3, 1.3, 0. ],\n",
       "       [5.1, 2.5, 3. , 1.1, 0. ],\n",
       "       [5.7, 2.8, 4.1, 1.3, 0. ],\n",
       "       [6.3, 3.3, 6. , 2.5, 1. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 1. ],\n",
       "       [7.1, 3. , 5.9, 2.1, 1. ],\n",
       "       [6.3, 2.9, 5.6, 1.8, 1. ],\n",
       "       [6.5, 3. , 5.8, 2.2, 1. ],\n",
       "       [7.6, 3. , 6.6, 2.1, 1. ],\n",
       "       [4.9, 2.5, 4.5, 1.7, 1. ],\n",
       "       [7.3, 2.9, 6.3, 1.8, 1. ],\n",
       "       [6.7, 2.5, 5.8, 1.8, 1. ],\n",
       "       [7.2, 3.6, 6.1, 2.5, 1. ],\n",
       "       [6.5, 3.2, 5.1, 2. , 1. ],\n",
       "       [6.4, 2.7, 5.3, 1.9, 1. ],\n",
       "       [6.8, 3. , 5.5, 2.1, 1. ],\n",
       "       [5.7, 2.5, 5. , 2. , 1. ],\n",
       "       [5.8, 2.8, 5.1, 2.4, 1. ],\n",
       "       [6.4, 3.2, 5.3, 2.3, 1. ],\n",
       "       [6.5, 3. , 5.5, 1.8, 1. ],\n",
       "       [7.7, 3.8, 6.7, 2.2, 1. ],\n",
       "       [7.7, 2.6, 6.9, 2.3, 1. ],\n",
       "       [6. , 2.2, 5. , 1.5, 1. ],\n",
       "       [6.9, 3.2, 5.7, 2.3, 1. ],\n",
       "       [5.6, 2.8, 4.9, 2. , 1. ],\n",
       "       [7.7, 2.8, 6.7, 2. , 1. ],\n",
       "       [6.3, 2.7, 4.9, 1.8, 1. ],\n",
       "       [6.7, 3.3, 5.7, 2.1, 1. ],\n",
       "       [7.2, 3.2, 6. , 1.8, 1. ],\n",
       "       [6.2, 2.8, 4.8, 1.8, 1. ],\n",
       "       [6.1, 3. , 4.9, 1.8, 1. ],\n",
       "       [6.4, 2.8, 5.6, 2.1, 1. ],\n",
       "       [7.2, 3. , 5.8, 1.6, 1. ],\n",
       "       [7.4, 2.8, 6.1, 1.9, 1. ],\n",
       "       [7.9, 3.8, 6.4, 2. , 1. ],\n",
       "       [6.4, 2.8, 5.6, 2.2, 1. ],\n",
       "       [6.3, 2.8, 5.1, 1.5, 1. ],\n",
       "       [6.1, 2.6, 5.6, 1.4, 1. ],\n",
       "       [7.7, 3. , 6.1, 2.3, 1. ],\n",
       "       [6.3, 3.4, 5.6, 2.4, 1. ],\n",
       "       [6.4, 3.1, 5.5, 1.8, 1. ],\n",
       "       [6. , 3. , 4.8, 1.8, 1. ],\n",
       "       [6.9, 3.1, 5.4, 2.1, 1. ],\n",
       "       [6.7, 3.1, 5.6, 2.4, 1. ],\n",
       "       [6.9, 3.1, 5.1, 2.3, 1. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 1. ],\n",
       "       [6.8, 3.2, 5.9, 2.3, 1. ],\n",
       "       [6.7, 3.3, 5.7, 2.5, 1. ],\n",
       "       [6.7, 3. , 5.2, 2.3, 1. ],\n",
       "       [6.3, 2.5, 5. , 1.9, 1. ],\n",
       "       [6.5, 3. , 5.2, 2. , 1. ],\n",
       "       [6.2, 3.4, 5.4, 2.3, 1. ],\n",
       "       [5.9, 3. , 5.1, 1.8, 1. ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv(\"iris_data\", sep = \",\", header = None)\n",
    "data2.columns =  ['sep_len', 'sep_wid', 'pet_len', 'pet_wid', 'class']\n",
    "data2 = data2[data2['class'] != 'Iris-setosa']\n",
    "data2['class'] = data2['class'].replace(['Iris-versicolor', 'Iris-virginica'], [0, 1])\n",
    "data2 = data2.to_numpy()\n",
    "\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "d8e72f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.01, n_iters=5, n_epochs = 1):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.n_epochs = n_epochs\n",
    "        self.activation_func = self.slenk\n",
    "        self.sigmoid = self.sigmoid\n",
    "        self.sigmoid2 = self.sigmoid2\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.paklaida = 0\n",
    "        \n",
    "        \n",
    "    def slenk(self, x):\n",
    "        return np.where(x>= 0, 1, 0)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return np.where((1/(1 + np.exp(-x))) >= 0.4, 1, 0)\n",
    "    \n",
    "    def sigmoid2(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def fit_slenk(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # init weights\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        y_ = np.array([1 if i > 0 else 0 for i in y])\n",
    "        print(\"TYPE IS \" + str(type(y_[1])))\n",
    "        predicted = np.zeros((y_.size), dtype =\"int64\")\n",
    "        for _e in range(self.n_epochs):\n",
    "            for _ in range(self.n_iters):\n",
    "                print(y_)\n",
    "                print(predicted)\n",
    "                if(not np.array_equal(y_,predicted)):\n",
    "                    predicted = np.zeros((y_.size), dtype = \"int64\")\n",
    "                    for idx, x_i in enumerate(X):\n",
    "                        linear_output = np.dot(x_i, self.weights) + self.bias\n",
    "                        y_predicted = self.activation_func(linear_output)\n",
    "                        #print(str(_) +\"real {\" + str(y_[idx]) + \"} , predicted {\"+ str(y_predicted) + \"}\")\n",
    "                        if(y_[idx] != y_predicted):\n",
    "                            update = self.lr * (y_[idx] - y_predicted)\n",
    "                            self.weights += update * x_i\n",
    "                            self.bias += update\n",
    "                        \n",
    "                        self.paklaida += (y_[idx] - y_predicted)**2\n",
    "                    \n",
    "                        linear_output = np.dot(x_i, self.weights) + self.bias\n",
    "                        y_predicted = self.activation_func(linear_output)\n",
    "                    \n",
    "                        predicted[idx] = y_predicted\n",
    "                else:\n",
    "                    print(\"RASTI SVORIAI\")\n",
    "                    break   \n",
    "                        \n",
    "                self.paklaida = self.paklaida/2\n",
    "                                    \n",
    "    def fit_sigmoid(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # init weights\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        y_ = np.array([1 if i > 0 else 0 for i in y])\n",
    "        \n",
    "        for _ in range(self.n_epochs):\n",
    "            for _ in range(self.n_iters):\n",
    "                for idx, x_i in enumerate(X):\n",
    "                    linear_output = np.dot(x_i, self.weights) + self.bias\n",
    "                    #print(linear_output)\n",
    "                    y_predicted = self.sigmoid(linear_output)\n",
    "                    \n",
    "                    y_predicted2 = self.sigmoid2(linear_output)\n",
    "                    self.paklaida += (y_[idx] - y_predicted2)**2\n",
    "                    \n",
    "                    if(y_predicted != y_[idx]):\n",
    "                        update = self.lr * (y_[idx] - y_predicted)\n",
    "                        self.weights += update * x_i\n",
    "                        self.bias += update\n",
    "                    \n",
    "                    \n",
    "                self.paklaida = self.paklaida/2\n",
    "                    \n",
    "                    \n",
    "    \n",
    "    def predict_slenk(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self.sigmoid(linear_output)\n",
    "        return y_predicted\n",
    "    \n",
    "    \n",
    "    def predict_sigmoid(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self.sigmoid(linear_output)\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "144d800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_x = data1[:,0:4]\n",
    "data1_y = data1[:,4]\n",
    "data2_x = data2[:,0:4]\n",
    "data2_y = data2[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "13f226f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE IS <class 'numpy.int64'>\n",
      "[1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
      " 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0\n",
      " 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
      " 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0\n",
      " 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1]\n",
      "[1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
      " 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0\n",
      " 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1]\n",
      "RASTI SVORIAI\n",
      "[-0.16 -0.6   0.78  0.34]\n",
      "-0.1\n",
      "3.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Klasifikavimo tikslumas')"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Slenkstine funkcija\n",
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "p = Perceptron(learning_rate=0.1, n_iters=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data1_x, data1_y, test_size = 0.2, random_state =123)\n",
    "p.fit_slenk(X_train, y_train)\n",
    "predictions = p.predict_slenk(X_test)\n",
    "\n",
    "print(p.weights)\n",
    "print(p.bias)\n",
    "print(p.paklaida)\n",
    "x = [0.1, 0.3, 0.5, 0.6, 0.8, 1]\n",
    "y = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "plt.plot(x,y)\n",
    "plt.xlabel(\"Mokymo greitis\")\n",
    "plt.ylabel(\"Klasifikavimo tikslumas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "e2104df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "aa95d133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.6 -6.   7.8  3.4]\n",
      "-1\n",
      "0.009015117523375417\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# SIGMOIDINE\n",
    "p = Perceptron(learning_rate= 1, n_iters = 10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data1_x, data1_y, test_size = 0.2, random_state =123)\n",
    "\n",
    "p.fit_sigmoid(X_train, y_train)\n",
    "predictions = p.predict_sigmoid(X_test)\n",
    "print(p.weights)\n",
    "print(p.bias)\n",
    "print(p.paklaida)\n",
    "\n",
    "print(accuracy(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "018a450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE IS <class 'numpy.int64'>\n",
      "[0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0\n",
      " 1 1 1 0 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0\n",
      " 1 1 1 0 1 1]\n",
      "[0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0\n",
      " 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0\n",
      " 1 1 1 0 1 1]\n",
      "[0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0\n",
      " 1 1 1 0 1 1]\n",
      "[0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0\n",
      " 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 0 1 0\n",
      " 1 1 1 0 1 1]\n",
      "RASTI SVORIAI\n",
      "[-8.4 -7.8 12.9  9.5]\n",
      "-5\n",
      "17.0\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Klasifikavimo tikslumas')"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SLENKSTINE SU DATA 2\n",
    "p = Perceptron(learning_rate = 1, n_iters = 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data2_x, data2_y, test_size = 0.2, random_state = 123)\n",
    "p.fit_slenk(X_train,y_train)\n",
    "predictions = p.predict_slenk(X_test)\n",
    "print(p.weights)\n",
    "print(p.bias)\n",
    "print(p.paklaida)\n",
    "x = [0.1, 0.3, 0.5, 0.6, 0.8, 1]\n",
    "y = [0.35, 0.35, 0.35, 0.35, 0.35, 0.35]\n",
    "print(accuracy(y_test, predictions))\n",
    "plt.plot(x,y)\n",
    "plt.xlabel(\"Mokymo greitis\")\n",
    "plt.ylabel(\"Klasifikavimo tikslumas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "faf6ec3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(predictions ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "ea51c143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real {0} , predicted {1}\n",
      "real {1} , predicted {0}\n",
      "real {0} , predicted {1}\n",
      "real {0} , predicted {0}\n",
      "real {0} , predicted {0}\n",
      "real {1} , predicted {0}\n",
      "real {1} , predicted {1}\n",
      "real {0} , predicted {1}\n",
      "real {1} , predicted {0}\n",
      "real {0} , predicted {1}\n",
      "real {0} , predicted {0}\n",
      "real {1} , predicted {0}\n",
      "real {0} , predicted {1}\n",
      "real {1} , predicted {0}\n",
      "real {1} , predicted {1}\n",
      "real {1} , predicted {1}\n",
      "real {1} , predicted {1}\n",
      "real {1} , predicted {1}\n",
      "real {1} , predicted {1}\n",
      "real {0} , predicted {1}\n",
      "real {0} , predicted {0}\n",
      "real {1} , predicted {0}\n",
      "real {0} , predicted {1}\n",
      "real {1} , predicted {0}\n",
      "real {0} , predicted {1}\n",
      "real {1} , predicted {1}\n",
      "real {0} , predicted {1}\n",
      "real {1} , predicted {0}\n",
      "real {0} , predicted {1}\n",
      "real {1} , predicted {0}\n",
      "real {0} , predicted {1}\n",
      "real {0} , predicted {0}\n",
      "real {1} , predicted {0}\n",
      "real {0} , predicted {1}\n",
      "real {0} , predicted {0}\n",
      "real {1} , predicted {0}\n",
      "real {0} , predicted {1}\n",
      "real {0} , predicted {0}\n",
      "real {1} , predicted {0}\n",
      "real {0} , predicted {1}\n",
      "real {0} , predicted {1}\n",
      "real {1} , predicted {0}\n",
      "real {0} , predicted {1}\n",
      "real {0} , predicted {0}\n",
      "real {0} , predicted {0}\n",
      "real {0} , predicted {0}\n",
      "real {1} , predicted {0}\n",
      "real {1} , predicted {1}\n",
      "real {1} , predicted {1}\n",
      "real {0} , predicted {1}\n",
      "real {0} , predicted {0}\n",
      "real {0} , predicted {0}\n",
      "real {0} , predicted {0}\n",
      "real {1} , predicted {0}\n",
      "real {0} , predicted {1}\n",
      "real {0} , predicted {1}\n",
      "real {1} , predicted {0}\n",
      "real {1} , predicted {1}\n",
      "real {1} , predicted {1}\n",
      "real {0} , predicted {1}\n",
      "real {0} , predicted {0}\n",
      "real {1} , predicted {0}\n",
      "real {1} , predicted {1}\n",
      "real {0} , predicted {1}\n",
      "real {1} , predicted {1}\n",
      "real {1} , predicted {1}\n",
      "real {0} , predicted {0}\n",
      "real {1} , predicted {1}\n",
      "real {1} , predicted {1}\n",
      "real {0} , predicted {0}\n",
      "real {0} , predicted {0}\n",
      "real {0} , predicted {0}\n",
      "real {1} , predicted {1}\n",
      "real {0} , predicted {0}\n",
      "real {1} , predicted {1}\n",
      "real {1} , predicted {1}\n",
      "real {1} , predicted {1}\n",
      "real {0} , predicted {0}\n",
      "real {1} , predicted {1}\n",
      "real {1} , predicted {1}\n",
      "[-6.5 -5.2 10.   7.5]\n",
      "-4\n",
      "17.915060456957224\n"
     ]
    }
   ],
   "source": [
    "# SIGMODINE SU DATA 2\n",
    "p = Perceptron(learning_rate = 1, n_iters = 1, n_epochs = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data2_x, data2_y, test_size = 0.2, random_state = 123)\n",
    "p.fit_sigmoid(X_train,y_train)\n",
    "predictions = p.predict_sigmoid(X_test)\n",
    "print(p.weights)\n",
    "print(p.bias)\n",
    "print(p.paklaida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "59636cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "c7425461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.array(y_test))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(predic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
